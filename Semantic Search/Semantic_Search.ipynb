{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bdfb2b2-490a-4f68-98a3-766dc28e0200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6136f16-f5af-4589-af12-379bfd3ced97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4de97db75945c981e5ab06b5385491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f66d42aa-d167-4093-8ee4-b60b03f3f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"GenAI internships require understanding embeddings and LLMs\",\n",
    "    \"Pizza is my favorite comfort food\",\n",
    "    \"I want to build a career in artificial intelligence\",\n",
    "    \"Deep learning is the foundation of modern generative models\",\n",
    "    \"I am feeling sleepy today\"\n",
    "]\n",
    "\n",
    "doc_embeddings = model.encode(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f18579-fc8a-4d48-81b4-fcc09eda65d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 384)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embeddings.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6699a43c-e1c7-4ab1-bc80-dd23d597616a",
   "metadata": {},
   "source": [
    "each document → 384-dim vector\n",
    "each vector → meaning, not text\n",
    "\n",
    "- IMPORTANT\n",
    "The number 384 is:\n",
    "not chosen by you\n",
    "fixed by model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44793d0d-6dae-47a2-9b93-5c81e75742f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 384)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I want an internship in GenAI\"\n",
    "query_embedding = model.encode([query])\n",
    "query_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04db7ab4-4ea0-49f6-8939-855a07f95cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66994077, 0.05132556, 0.41775212, 0.1602646 , 0.05814601]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = cosine_similarity(query_embedding, doc_embeddings)\n",
    "similarities"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1894647c-61e7-4622-b2cb-e1511d27bfd0",
   "metadata": {},
   "source": [
    "Shape:\n",
    "rows → queries (here only 1)\n",
    "columns → documents\n",
    "Each value corresponds to same index in documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8872340-9135-492a-86d5-2609819aebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenAI internships require understanding embeddings and LLMs 0.66994077\n",
      "I want to build a career in artificial intelligence 0.41775212\n",
      "Deep learning is the foundation of modern generative models 0.1602646\n",
      "I am feeling sleepy today 0.05814601\n",
      "Pizza is my favorite comfort food 0.051325563\n"
     ]
    }
   ],
   "source": [
    "top_indices = np.argsort(similarities[0])[::-1]\n",
    "\n",
    "for idx in top_indices:\n",
    "    print(documents[idx], similarities[0][idx])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09d6bf86-07a0-49a4-8a8b-0f7f5d4caf60",
   "metadata": {},
   "source": [
    "argsort DOES NOT sort values\n",
    "It sorts indices based on values.\n",
    "argsort gives ascending order (low → high).\n",
    "so we reverse it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9643a72a-973b-4aa2-88de-789549ca672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ffb3e40-f0ae-4d8c-af53-e5de810f9b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenAI internships require understanding embeddings and LLMs\n",
      "I want to build a career in artificial intelligence\n",
      "Deep learning is the foundation of modern generative models\n"
     ]
    }
   ],
   "source": [
    "#Take top_k\n",
    "top_indices = top_indices[:top_k]\n",
    "\n",
    "for idx in top_indices:\n",
    "    print(documents[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "460205c3-3b0b-448f-b5fb-a9ca10d5793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74b6ccef-cfad-4578-86d9-5198dbeaaff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = similarities.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec23357f-4ad6-4883-9d86-f810eeeb3bd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Apply threshold\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m final_docs = \u001b[43m[\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtop_indices\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msimilarities\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m]\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Apply threshold\u001b[39;00m\n\u001b[32m      2\u001b[39m final_docs = [\n\u001b[32m      3\u001b[39m     documents[i]\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m top_indices\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msimilarities\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m >= threshold\n\u001b[32m      6\u001b[39m ]\n",
      "\u001b[31mIndexError\u001b[39m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "#Apply threshold\n",
    "final_docs = [\n",
    "    documents[i]\n",
    "    for i in top_indices\n",
    "    if similarities[0][i] >= threshold\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8fb4914-d8f8-4d71-84ae-55762f691966",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfinal_docs\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'final_docs' is not defined"
     ]
    }
   ],
   "source": [
    "print(final_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8055e357-9f17-482c-a866-17e1608775b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Doc A', 'Doc B']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "similarities = np.array([0.82, 0.78, 0.61, 0.22, 0.05])\n",
    "documents = [\n",
    "    \"Doc A\",\n",
    "    \"Doc B\",\n",
    "    \"Doc C\",\n",
    "    \"Doc D\",\n",
    "    \"Doc E\"\n",
    "]\n",
    "\n",
    "top_k = 3\n",
    "threshold = 0.70\n",
    "\n",
    "# Step 1: Get indices sorted by similarity (descending)\n",
    "sorted_indices = np.argsort(similarities)[::-1]\n",
    "\n",
    "# Step 2: Take top_k\n",
    "top_indices = sorted_indices[:top_k]\n",
    "\n",
    "# Step 3: Apply threshold\n",
    "final_docs = [\n",
    "    documents[i]\n",
    "    for i in top_indices\n",
    "    if similarities[i] >= threshold\n",
    "]\n",
    "\n",
    "print(final_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "533685dc-deb7-4c91-b987-c2853b3d5608",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(final_docs) == 0:\n",
    "    print(\"I don't have enough information to answer this.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9857c4-50b3-4db9-97c3-b20eb2cc16ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
